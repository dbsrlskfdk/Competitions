{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import tempfile\n",
    "import keyword\n",
    "import subprocess\n",
    "from collections import Counter\n",
    "\n",
    "import polars as pl\n",
    "import torch\n",
    "\n",
    "from transformers import set_seed\n",
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model, Test Data Load and Initialize etc.\n",
    "\n",
    "- AIMO2 Reference File Needed : `../data/reference.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "model_name = \"Qwen/Qwen2.5-Math-1.5B-Instruct\"\n",
    "test_data = pl.read_csv(os.path.join(os.path.pardir, \"data\", \"reference.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['problem']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_memory(deep=False):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LLM(model_name,\n",
    "            trust_remote_code=True,\n",
    "            dtype=\"bfloat16\",\n",
    "            # dtype=\"half\", # When using AWQ Model\n",
    "            max_num_seqs=8,\n",
    "            max_model_len=4096,\n",
    "            tensor_parallel_size=1,\n",
    "            gpu_memory_utilization=0.8,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = model.get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(\n",
    "    temperature=0.7,              # randomness of the sampling\n",
    "    min_p=0.01,\n",
    "    top_p=0.8,\n",
    "    skip_special_tokens=True,     # Whether to skip special tokens in the output.\n",
    "    max_tokens=2400,\n",
    "    # stop=[\"```\\n\"],\n",
    "    include_stop_str_in_output=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define require functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_python_code(text):\n",
    "    pattern = r'```python\\s*(.*?)\\s*```'\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    return \"\\n\\n\".join(matches)\n",
    "\n",
    "def extract_boxed_text(text):\n",
    "    pattern = r'oxed{(.*?)}'\n",
    "    matches = re.findall(pattern, text)\n",
    "    if not matches:\n",
    "        return \"\"\n",
    "    return matches[0]\n",
    "\n",
    "def select_answer(answers):\n",
    "    counter = Counter()\n",
    "    for answer in answers:\n",
    "        try:\n",
    "            if int(answer) == float(answer):\n",
    "                counter[int(answer)] += 1 + random.random() / 1_000\n",
    "        except:\n",
    "            pass\n",
    "    if not counter:\n",
    "        return 210\n",
    "    _, answer = sorted([(v,k) for k,v in counter.items()], reverse=True)[0]\n",
    "    return answer%1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code excution Tool\n",
    "class PythonREPL:\n",
    "    def __init__(self, timeout=5):\n",
    "        self.timeout = timeout\n",
    "\n",
    "    def __call__(self, query):\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            temp_file_path = os.path.join(temp_dir, \"tmp.py\")\n",
    "            with open(temp_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(query)\n",
    "            \n",
    "            try:\n",
    "                result = subprocess.run(\n",
    "                    [\"python3\", temp_file_path],\n",
    "                    capture_output=True,\n",
    "                    check=False,\n",
    "                    text=True,\n",
    "                    timeout=self.timeout,\n",
    "                )\n",
    "            except subprocess.TimeoutExpired:\n",
    "                return False, f\"Execution timed out after {self.timeout} seconds.\"\n",
    "\n",
    "            stdout = result.stdout.strip()\n",
    "            stderr = result.stderr.strip()\n",
    "\n",
    "            if result.returncode == 0:\n",
    "                return True, stdout\n",
    "            else:\n",
    "                # Process the error message to remove the temporary file path\n",
    "                # This makes the error message cleaner and more user-friendly\n",
    "                error_lines = stderr.split(\"\\n\")\n",
    "                cleaned_errors = []\n",
    "                for line in error_lines:\n",
    "                    if temp_file_path in line:\n",
    "                        # Remove the path from the error line\n",
    "                        line = line.replace(temp_file_path, \"<temporary_file>\")\n",
    "                    cleaned_errors.append(line)\n",
    "                cleaned_error_msg = \"\\n\".join(cleaned_errors)\n",
    "                # Include stdout in the error case\n",
    "                combined_output = f\"{stdout}\\n{cleaned_error_msg}\" if stdout else cleaned_error_msg\n",
    "                return False, combined_output\n",
    "            \n",
    "\n",
    "def process_python_code(query):\n",
    "    # Add import statements\n",
    "    # Also print variables if they are not inside any indentation\n",
    "    query = \"import math\\nimport numpy as np\\nimport sympy as sp\\n\" + query\n",
    "    current_rows = query.strip().split(\"\\n\")\n",
    "    new_rows = []\n",
    "    for row in current_rows:\n",
    "        new_rows.append(row)\n",
    "        if not row.startswith(\" \") and \"=\" in row:\n",
    "            variables_to_print = row.split(\"=\")[0].strip()\n",
    "            for variable_to_print in variables_to_print.split(\",\"):\n",
    "                variable_to_print = variable_to_print.strip()\n",
    "                if variable_to_print.isidentifier() and not keyword.iskeyword(variable_to_print):\n",
    "                    if row.count(\"(\") == row.count(\")\") and row.count(\"[\") == row.count(\"]\"):\n",
    "                        # TODO: use some AST to parse code\n",
    "                        new_rows.append(f'\\ntry:\\n    print(f\"{variable_to_print}={{str({variable_to_print})[:100]}}\")\\nexcept:\\n    pass\\n')\n",
    "    return \"\\n\".join(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_first_msg(question, i):\n",
    "    cycle_len = 2\n",
    "\n",
    "    if i % cycle_len:\n",
    "        # When odd index number, use CoT Prompt\n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": \"Please reason step by step, and put your final answer within \\\\boxed{}.\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]\n",
    "    else:\n",
    "        # When even index number, use TIR(Tool-Integrated Reasoning) Prompt\n",
    "        return [\n",
    "                {\"role\": \"system\", \"content\": \"Please integrate natural language reasoning with programs to solve the problem above, and, put your final answer within \\\\boxed{}.\"},\n",
    "                {\"role\": \"user\", \"content\": question + \"\\n\\nBegin your answer by importing sympy.\"}\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_message(messages):\n",
    "    prompts = [\n",
    "        tokenizer.apply_chat_template(\n",
    "            message,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "        for message in messages\n",
    "    ]\n",
    "\n",
    "    outputs = model.generate(prompts=prompts, sampling_params=sampling_params)\n",
    "    for message, output in zip(messages, outputs):\n",
    "        message.append({\"role\" : \"assistant\", \"content\" : output.outputs[0].text})\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_batch_message(messages):\n",
    "    extracted_answer = []\n",
    "    messages_to_keep = []\n",
    "    for message in messages:\n",
    "        answer = extract_boxed_text(message[-1][\"content\"])\n",
    "        if answer:\n",
    "            extracted_answer.append(answer)\n",
    "        else:\n",
    "            messages_to_keep.append(message)\n",
    "    return messages_to_keep, extracted_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_batch_message(messages):\n",
    "    for message in messages:\n",
    "        python_code = extract_python_code(message[-1]['content'])\n",
    "        python_code = process_python_code(python_code)\n",
    "\n",
    "        print(\"Python Excution State : \", end='')\n",
    "        try:\n",
    "            print('c', end='')\n",
    "            is_success, output = PythonREPL()(python_code)\n",
    "            if is_success:\n",
    "                print('o', end='')\n",
    "            else:\n",
    "                print('e', end='')\n",
    "        except Exception as e:\n",
    "            print('f', end='')\n",
    "            output = str(e)\n",
    "        \n",
    "        print(f\"\\n{python_code}\\n\")\n",
    "        print(f\"Excution Result : {output}\\n\")\n",
    "        message.append({\"role\" : \"user\", \"content\" : \"```output\\n\"+output+\"\\n```\\n\\nPlease rigorously check whether the output makes sense.\"}) # Python Excution Result Double check\n",
    "    \n",
    "    return messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_question(question : str, maj_n: int = 32, call_n: int = 4):\n",
    "    question += \"\\nIf ther final answer is a number larger than 1 million, take modulo 1000.\"\n",
    "    messages = [create_first_msg(question, i) for i in range(maj_n)] # odd `i` is CoT / even `i` is TIR\n",
    "\n",
    "    extracted_answers = []\n",
    "    for _ in range(call_n):\n",
    "        messages = generate_batch_message(messages)\n",
    "        messages, answers = filter_batch_message(messages)\n",
    "        extracted_answers.extend(answers)\n",
    "        if not messages:\n",
    "            break\n",
    "        messages = execute_batch_message(messages) # When you use TIR, add double check instuction after excute python code. => Only using CoT, you can skip this step for setting `call_n` to 1.\n",
    "    print(extracted_answers)\n",
    "    answer = select_answer(extracted_answers)\n",
    "    print(answer)\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for i in range(len(test_data['problem'])):\n",
    "    test_question = test_data['problem'][i]\n",
    "    test_gt = test_data['answer'][i]\n",
    "    print(test_question)\n",
    "    answer = predict_single_question(test_question, maj_n=64, call_n=4)\n",
    "    print(f\"GT : {test_gt}, Predict : {answer}\")\n",
    "    predicted.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df = pl.DataFrame({\n",
    "    \"predicted\" : predicted,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated = pl.concat([test_data, predicted_df], how=\"horizontal\")\n",
    "print(f\"Accuracy : {len(concatenated.filter(pl.col('answer') == pl.col('predicted'))) / len(concatenated) * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated.write_csv(os.path.join(os.path.pardir, \"predictions\", f\"{model_name.split(\"/\")[-1]}_prediction.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold Generation\n",
    "\n",
    "1.\n",
    "To solve the problem, we need to find the greatest possible length of segment \\(CD\\), where \\(D\\) is the foot of the perpendicular from \\(C\\) to the line \\(AB\\). Given that \\(AB = 120\\) and the circumradius \\(R = 100\\), we can use the properties of the circumcircle and the triangle to find the maximum length of \\(CD\\).\n",
    "\n",
    "The length \\(CD\\) is maximized when \\(C\\) is at the highest possible position relative to \\(AB\\). This happens when \\(C\\) is on the line perpendicular to \\(AB\\) passing through the circumcenter \\(O\\), and \\(C\\) is on the opposite side of \\(AB\\) relative to \\(O\\).\n",
    "\n",
    "The distance from the circumcenter \\(O\\) to the chord \\(AB\\) can be calculated using the formula:\n",
    "\\[ d = \\sqrt{R^2 - \\left(\\frac{AB}{2}\\right)^2} \\]\n",
    "where \\(R\\) is the circumradius and \\(AB\\) is the length of the chord.\n",
    "\n",
    "Let's calculate \\(d\\):\n",
    "\\[ d = \\sqrt{100^2 - \\left(\\frac{120}{2}\\right)^2} = \\sqrt{100^2 - 60^2} = \\sqrt{10000 - 3600} = \\sqrt{6400} = 80 \\]\n",
    "\n",
    "The maximum length of \\(CD\\) is then the sum of the circumradius \\(R\\) and the distance \\(d\\):\n",
    "\\[ CD = R + d = 100 + 80 = 180 \\]\n",
    "\n",
    "Let's confirm this with sympy:\n",
    "\n",
    "```python\n",
    "import sympy as sp\n",
    "\n",
    "# Given values\n",
    "AB = 120\n",
    "R = 100\n",
    "\n",
    "# Calculate the distance from the circumcenter to the chord AB\n",
    "d = sp.sqrt(R**2 - (AB/2)**2)\n",
    "\n",
    "# Calculate the maximum length of CD\n",
    "CD_max = R + d\n",
    "\n",
    "print(CD_max)\n",
    "```\n",
    "```output\n",
    "180.000000000000\n",
    "```\n",
    "The greatest possible length of segment \\(CD\\) is \\(\\boxed{180}\\).\n",
    "\n",
    "\n",
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
